from selenium import webdriver
from selenium.webdriver.chrome.service import Service
import csv
from selenium.webdriver.common.by import By
# 设置ChromeDriver路径及参数
chromedriver_path = 'C:\Program Files\Google\Chrome\Application\chromedriver.exe'
options = webdriver.ChromeOptions()
# options.add_argument('--headless')  # 无界面运行Chrome

# 初始化webdriver
s = Service(chromedriver_path)
wd = webdriver.Chrome(service=s, options=options)

# 创建CSV文件写入器，用于保存招聘和求职信息
job_writer = csv.writer(open('result1-1.csv', 'w', encoding='utf-8', newline=''))
job_writer.writerow(['招聘信息ID', '公司名称', '招聘岗位', '城市', '薪资'])

resume_writer = csv.writer(open('result1-2.csv', 'w', encoding='utf-8', newline=''))
resume_writer.writerow(['求职者ID', '姓名', '城市', '求职意向', '期望薪资'])

# 爬取“找工作”页面和“找人才”页面的数据
urls = [
    'https://www.5iai.com/#/jobList',  # 找工作页面
    'https://www.5iai.com/#/moreResume'  # 找人才页面
]
for url in urls:
    # 打开起始页面
    wd.get(url)

    if url == 'https://www.5iai.com/#/jobList':
        # 提取所有招聘信息数据并保存到CSV文件中
        job_items = wd.find_elements(By.CSS_SELECTOR, 'el-radio-button__inner')
        for job_item in job_items:
            job_id = job_item.find_element(By.CSS_SELECTOR, 'cTxt').get_attribute('href').split('/')[-1]
            company_name = job_item.find_element(By.CSS_SELECTOR, 'tit').text.strip()
            job_title = job_item.find_element(By.CSS_SELECTOR, 'position').text.strip()
            city = job_item.find_element(By.CSS_SELECTOR, 'cTxt').text.strip()
            salary = job_item.find_element(By.CSS_SELECTOR, 'datePay').text.strip()
            job_writer.writerow([job_id, company_name, job_title, city, salary])
    else:
        # 提取所有求职信息数据并保存到CSV文件中
        resume_items = wd.find_elements(By.CSS_SELECTOR, 'expectPosition')
        for resume_item in resume_items:
            resume_id = resume_item.find_element(By.CSS_SELECTOR, 'position').get_attribute('href').split('/')[-1]
            name = resume_item.find_element(By.CSS_SELECTOR, 'position').text.strip()
            city = resume_item.find_element(By.CSS_SELECTOR, 'intro').text.strip()
            intention = resume_item.find_element(By.CSS_SELECTOR, 'expectPosition').text.strip()
            expect_salary = resume_item.find_element(By.CSS_SELECTOR, '.salary').text.strip()
            resume_writer.writerow([resume_id, name, city, intention, expect_salary])

    print(f'爬取"{url}"页面的招聘和求职信息完成！')

wd.quit()
